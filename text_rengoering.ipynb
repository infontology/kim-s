{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.tokenize.punkt\n",
    "# Utgår tills vidare från https://machinelearningmastery.com/clean-text-machine-learning-python/ \n",
    "# Det som saknas i nltk laddas ner via konstigt GUI direkt i Python3: >>> import nltk >>> nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Library\n",
      "of Sweden\n",
      "\n",
      "Denna bok digitaliserades på Kungl.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'sou_1944.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into sentences\n",
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5754"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'k', 'r', 'i', 's', 'e', 'n', '.', 'Del', '4', '.', 'T', 'i', 'd', 'e', 'n', 'j', 'u', 'l', 'i', '1942—juni', '1943', '.', 'I', 'd', 'u', 'n', '.', '559', 's.', 'F', 'o', '.', '12', '.', 'U', 't', 'r', 'e', 'd', 'n', 'i', 'n', 'g', 'a', 'r', 'a', 'n', 'g', 'å', 'e', 'n', 'd', 'e', 'e', 'k', 'o', 'n', 'o', 'm', 'i', 's', 'k', 'e', 'f', 't', 'e', 'r', 'k', 'r', 'i', 'g', 's', 'p', 'l', 'a', 'n', 'e', 'r', 'i', 'n', 'g', '.', '2', '.', 'I', 'n', 'v', 'e', 's', 't', 'e', 'r', 'i', 'n', 'g', 's', 'u', 't', 'r']\n"
     ]
    }
   ],
   "source": [
    "filename = 'sou_1944.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens[900:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['National', 'Library', 'of', 'Sweden', 'Denna', 'bok', 'digitaliserades', 'på', 'Kungl', 'biblioteket', 'år', 'S', 'T', 'A', 'T', 'E', 'N', 'S', 'O', 'F', 'F', 'E', 'N', 'T', 'L', 'I', 'G', 'A', 'U', 'T', 'R', 'E', 'D', 'N', 'I', 'N', 'G', 'A', 'R', 'SOCIALDEPARTEMENTET', 'SOCIALVÅRDSKOMMITTÉNS', 'BETÄNKANDE', 'IX', 'U', 'T', 'R', 'E', 'D', 'N', 'I', 'N', 'G', 'OCH', 'FÖRSLAG', 'ANGÅENDE', 'REVISION', 'AV', 'LAGSTIFTNINGEN', 'OM', 'BARNAVÅRDSANSTALTER', 'OCH', 'FOSTERBARNSVÅRD', 'S', 'T', 'O', 'C', 'K', 'H', 'O', 'L', 'M', 'Statens', 'offentliga', 'utredningar', 'K', 'r', 'o', 'n', 'o', 'o', 'g', 'i', 's', 'k', 'jf', 'ö', 'r', 't', 'e', 'c', 'k', 'n', 'i', 'g', 'J', 'o', 'r', 'd', 'b', 'r', 'u', 'k', 's', 'b', 'e', 'f', 'o', 'l', 'k', 'n', 'i', 'n', 'g', 'e', 'n', 's', 'l', 'e', 'v', 'n', 'a', 'd', 's', 'k', 'o', 's', 't', 'n', 'a', 'd', 'e', 'r', 'Av', 'E', 'L', 'i', 'n', 'd', 'a', 'h', 'l', 'o', 'c', 'h', 'L', 'L', 'e', 'm', 'n', 'e', 'M', 'a', 'r', 'c', 'u', 's', 'J', 'o', 'B', 'e', 't', 'ä', 'n', 'k', 'a', 'n', 'd', 'e', 'm', 'e', 'd', 'förslag', 'a', 'n', 'g', 'å', 'e', 'n', 'd', 'e', 'l', 'å', 'n', 'g', 't', 'j', 'ä', 'n', 's', 't', 'u', 'n', 'd', 'e', 'r', 'b', 'e', 'f', 'ä', 'l', 'm', 'B', 'e', 'c', 'k', 'm', 'a', 'n', 'F', 'ö', 'B', 'e', 't', 'ä', 'n', 'k', 'a', 'n', 'd', 'e', 'a', 'n', 'g', 'å', 'e', 'n', 'd', 'e', 'n', 'y', 'k', 't', 'e', 'r', 'h', 'e', 't', 's', 't', 'i', 'l', 'l', 's', 't', 'å', 'n', 'd', 'e', 't', 'u', 'n', 'd', 'e', 'r', 'krigså', 'r', 'e', 'n', 'M', 'a', 'r', 'c', 'u', 's', 'F', 'i', 'P', 'r', 'o', 'm', 'e', 'm', 'o', 'r', 'i', 'a', 'm', 'o', 'd', 'förslag', 't', 'i', 'l', 'l', 'l', 'a', 'g', 'm', 'e', 'd', 'b', 'e', 's', 't', 'ä', 'm', 'm', 'e', 'l', 's', 'e', 'r', 'om', 'allmänna', 'behörighetsvillkor', 'för', 'vissa', 'k', 'o', 'm', 'm', 'u', 'n', 'a', 'l', 'a', 'u', 'p', 'p', 'd', 'r', 'a', 'g', 'm', 'm', 'Hseggström', 'B', 'e', 't', 'ä', 'n', 'k', 'a', 'n', 'd', 'e', 'm', 'e', 'd', 'förslag', 'till', 'c', 'i', 'v', 'i', 'l', 'f', 'ö', 'r', 's', 'v', 'a', 'r', 's', 'l', 'a', 'g', 'n', 'i', 'm', 'B', 'e', 'c', 'k', 'm', 'a', 'n', 'B', 'e', 't', 'ä', 'n', 'k', 'a', 'n', 'd', 'e', 'm', 'e', 'd', 'förslag', 'till', 'b', 'y', 'o', 'r', 'd', 'n', 'i', 'n', 'g', 'a', 'r', 'o', 'c', 'h', 'i', 'n', 's', 't', 'r', 'u', 'k', 't', 'i', 'o', 'n', 'e', 'r', 'för', 'o', 'r', 'd', 'n', 'i', 'n', 'g', 's', 'm', 'a', 'n', 'n', 'e', 'n', 'i', 'l', 'a', 'p', 'p', 'b', 'y', 'a', 'r', 'n', 'a', 'M', 'a', 'r', 'c', 'u', 's', 'Jo', 'U', 't', 'r', 'e', 'd', 'n', 'i', 'n', 'g', 'a', 'r', 'a', 'n', 'g', 'å', 'e', 'n', 'd', 'e', 'e', 'k', 'o', 'n', 'o', 'm', 'i', 's', 'k', 'e', 'f', 't', 'e', 'r', 'k', 'r', 'i', 'g', 's', 'p', 'l', 'a', 'n', 'e', 'r', 'i', 'n', 'g', 'M', 'a', 'r', 'c', 'u', 's', 'F', 'i', 'B', 'e', 't', 'ä', 'n', 'k', 'a', 'n', 'd', 'e', 'm', 'e', 'd', 'förslag', 'a', 'n', 'g', 'å', 'e', 'n', 'd', 'e', 'r', 'e', 'v', 'i', 's', 'i', 'o', 'n', 'a', 'v', 'r', 'i', 'k', 's', 'd', 'a', 'g', 'e', 'n', 's', 'a', 'r', 'b', 'e', 't', 's', 'f', 'o', 'r', 'm', 'e', 'r', 'N', 'o', 'r', 's', 't', 'e', 'd', 't', 'J', 'u', 'P', 'r', 'o', 'c', 'e', 's', 's', 'l', 'a', 'g', 'b', 'e', 'r', 'e', 'd', 'u', 'i', 'n', 'g', 'e', 'n', 's', 'förslag', 'till', 'l', 'a', 'g', 'o', 'm', 'i', 'n', 'f', 'ö', 'r', 'a', 'n', 'd', 'e', 'av', 'n', 'y', 'a', 'r', 'ä', 't', 't', 'e', 'g', 'å', 'n', 'g', 's', 'b', 'a', 'l', 'k', 'e', 'n', 'm', 'm', 'L', 'a', 'g', 't', 'e', 'x', 't', 'N', 'o', 'r', 's', 't', 'e', 'd', 't', 'v', 'i', 'i', 'j', 'J', 'u', 'P', 'r', 'o', 'c', 'e', 's', 's', 'l', 'a', 'g', 'b', 'e', 'r', 'e', 'd', 'n', 'i', 'n', 'g', 'e', 'n', 's', 'f', 'ö', 'r', 's', 'l', 'a', 'g', 'till', 'l', 'a', 'g', 'o', 'm', 'i', 'n', 'f', 'ö', 'r', 'a', 'n', 'd', 'e', 'a', 'v', 'n', 'y', 'a', 'r', 'ä', 't', 't', 'e', 'g', 'å', 'n', 'g', 's', 'b', 'a', 'l', 'k', 'e', 'n', 'm', 'm', 'M', 'o', 't', 'i', 'v', 'm', 'm', 'N', 'o', 'r', 's', 't', 'e', 'd', 't', 'J', 'u', 'S', 't', 'a', 't', 's', 'm', 'a', 'k', 't', 'e', 'r', 'n', 'a', 'o', 'c', 'h', 'f', 'o', 'l', 'k', 'h', 'u', 's', 'h', 'å', 'l', 'l', 'n', 'i', 'n', 'g', 'e', 'n', 'u', 'n', 'd', 'e', 'r', 'd', 'e', 'n', 'till', 'följd', 'a', 'v', 's', 't', 'o', 'r', 'm', 'a', 'k', 't', 's', 'k', 'r', 'i', 'g', 'e', 't', 'i', 'n', 't', 'r', 'ä', 'd', 'd', 'a', 'k', 'r', 'i', 's', 'e', 'n', 'Del', 'T', 'i', 'd', 'e', 'n', 'j', 'u', 'l', 'i', 'I', 'd', 'u', 'n', 'F', 'o', 'U', 't', 'r', 'e', 'd', 'n', 'i', 'n', 'g', 'a', 'r', 'a', 'n', 'g', 'å', 'e', 'n', 'd', 'e', 'e', 'k', 'o', 'n', 'o', 'm', 'i', 's', 'k', 'e', 'f', 't', 'e', 'r', 'k', 'r', 'i', 'g', 's', 'p', 'l', 'a', 'n', 'e', 'r', 'i', 'n', 'g', 'I', 'n', 'v', 'e', 's', 't', 'e', 'r', 'i', 'n', 'g', 's', 'u', 't', 'r', 'e', 'd', 'n', 'i', 'n', 'g', 'e', 'n', 's', 'b', 'e', 't', 'ä', 'n', 'k', 'a', 'n', 'd', 'e', 'm', 'e', 'd', 'förslag', 'till', 'i', 'n', 'v', 'e', 's', 't', 'e', 'r', 'i', 'n', 'g', 's', 'r', 'e', 's', 'e', 'r', 'v', 'av', 'statliga', 'k', 'o', 'm', 'm', 'u', 'n', 'a', 'l', 'a', 'o', 'c', 'h', 's', 't', 'a', 't', 's', 'u', 'n', 'd', 'e', 'r', 's', 't', 'ö', 'd', 'd', 'a', 'a', 'n', 'l', 'ä', 'g', 'g', 'n', 'i', 'n', 'g', 's', 'a', 'r', 'b', 'e', 't', 'e', 'n', 'f', 'ö', 'r', 'b', 'u', 'd', 'g', 'e', 't', 'å', 'r', 'e', 't', 'M', 'a', 'r', 'c', 'u', 's', 'F', 'i', 'U', 't', 'r', 'e', 'd', 'n', 'i', 'n', 'g', 'a', 'r']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'sou_1944.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# remove all tokens that are not alphabetic\n",
    "words = [word for word in tokens if word.isalpha()]\n",
    "print(words[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['och', 'det', 'att', 'i', 'en', 'jag', 'hon', 'som', 'han', 'på', 'den', 'med', 'var', 'sig', 'för', 'så', 'till', 'är', 'men', 'ett', 'om', 'hade', 'de', 'av', 'icke', 'mig', 'du', 'henne', 'då', 'sin', 'nu', 'har', 'inte', 'hans', 'honom', 'skulle', 'hennes', 'där', 'min', 'man', 'ej', 'vid', 'kunde', 'något', 'från', 'ut', 'när', 'efter', 'upp', 'vi', 'dem', 'vara', 'vad', 'över', 'än', 'dig', 'kan', 'sina', 'här', 'ha', 'mot', 'alla', 'under', 'någon', 'eller', 'allt', 'mycket', 'sedan', 'ju', 'denna', 'själv', 'detta', 'åt', 'utan', 'varit', 'hur', 'ingen', 'mitt', 'ni', 'bli', 'blev', 'oss', 'din', 'dessa', 'några', 'deras', 'blir', 'mina', 'samma', 'vilken', 'er', 'sådan', 'vår', 'blivit', 'dess', 'inom', 'mellan', 'sådant', 'varför', 'varje', 'vilka', 'ditt', 'vem', 'vilket', 'sitta', 'sådana', 'vart', 'dina', 'vars', 'vårt', 'våra', 'ert', 'era', 'vilkas']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('swedish')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['national', 'library', 'sweden', 'denna', 'bok', 'digitaliserades', 'på', 'kungl', 'biblioteket', 'år', 'j', 'e', 'n', 'f', 'f', 'e', 'n', 'l', 'g', 'u', 'r', 'e', 'n', 'n', 'g', 'r', 'socialdepartementet', 'socialvårdskommitténs', 'betänkande', 'ix', 'u', 'r', 'e', 'n', 'n', 'g', 'och', 'förslag', 'angående', 'revision', 'av', 'lagstiftningen', 'om', 'barnavårdsanstalter', 'och', 'fosterbarnsvård', 'c', 'k', 'h', 'l', 'statens', 'offentliga', 'utredningar', 'k', 'r', 'n', 'g', 'k', 'jf', 'ö', 'r', 'e', 'c', 'k', 'n', 'g', 'j', 'r', 'b', 'r', 'u', 'k', 'b', 'e', 'f', 'l', 'k', 'n', 'n', 'g', 'e', 'n', 'l', 'e', 'v', 'n', 'k', 'n', 'e', 'r', 'av', 'e', 'l', 'n', 'h', 'l', 'c', 'h', 'l', 'l']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'sou_1944.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "# remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in tokens]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words = [word for word in stripped if word.isalpha()]\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [w for w in words if not w in stop_words]\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nation', 'librari', 'of', 'sweden', 'denna', 'bok', 'digitaliserad', 'på', 'kungl', '.', 'biblioteket', 'år', '2012', '.J', 'S', 'T', 'A', 'T', 'E', 'N', 'S', 'O', 'F', 'F', 'E', 'N', 'T', 'L', 'I', 'G', 'A', 'U', 'T', 'R', 'E', 'D', 'N', 'I', 'N', 'G', 'A', 'R', '1', '9', '4', '4', ':', '34', 'socialdepartementet', 'socialvårdskommittén', 'betänkand', 'IX', ':', 'U', 'T', 'R', 'E', 'D', 'N', 'I', 'N', 'G', 'och', 'förslag', 'angåend', 'revis', 'AV', 'lagstiftningen', 'OM', 'barnavårdsanstalt', 'och', 'fosterbarnsvård', 'S', 'T', 'O', 'C', 'K', 'H', 'O', 'L', 'M', '19', '4', '4', 'staten', 'offentliga', 'utredningar', '1944', 'K', 'r', 'o', 'n', 'o', '1', 'o', 'g', 'i', 's', 'k', 'jf']\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "filename = 'sou_1944.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "# stemming of words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "stemmed = [porter.stem(word) for word in tokens]\n",
    "print(stemmed[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
